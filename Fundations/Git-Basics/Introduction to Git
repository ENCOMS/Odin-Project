Topic: Introduction to Git

Link: https://www.theodinproject.com/lessons/foundations-introduction-to-git


What is Git?
------------
By far, the most widely used modern version control system in the world today is Git. Git is a mature, actively maintained open source project originally developed in 2005 by Linus Torvalds, the famous creator of the Linux operating system kernel.

A staggering number of software projects rely on Git for version control, including commercial projects as well as open source. Developers who have worked with Git are well represented in the pool of available software development talent and it works well on a wide range of operating systems and IDEs (Integrated Development Environments).

Having a distributed architecture, Git is an example of a DVCS (hence Distributed Version Control System). Rather than have only one single place for the full version history of the software as is common in once-popular version control systems like CVS or Subversion (also known as SVN), in Git, every developer's working copy of the code is also a repository that can contain the full history of all changes.

In addition to being distributed, Git has been designed with performance, security and flexibility in mind.




Version Control
---------------
It allows you to revert selected files back to a previus state, revert the entrire project back to a previous state, compare changes over time, see who last modified something that might be causing a problem, who introduced an issue and when, and more. Using a VCS also generally means that if you screw things up or lose files, you can easily recover. In addition, you get all this for very little overhead.

Types of Version control systems:

Local Version Control Systems:

This is the first and most common aproach, since it try to resolve the issue that is prone to error that is try to keep all the copys of the files in the correct order and folder.

For this Local VCS had a simple database that kept all the changes to files under revision control.

    Local Computer

Checkout    Version Database
File-----------Version3
               Version2
               Version1

One of the most commons are the RCS that still are bundle in many computers today, they save differences bettween files in a special format and it can re-create what any file looke like at any point in time by adding up all the patches.



Centralized Version Control Systems:

It surge from the need of people to collaborate with each other in a project.
These systems (such as CVS, Subversion, and Perforce) have a single server that contains all the versioned files, and a number of clients that check out files from that central place. For many years, this has been the standard for version control.

    Central VCS Server

Computer A   Version Database
File-----------Version5
               Version4
               Version3
Computer B     Version2
File---------- Version1

Advantage of CVCS:
- Everyone knows to a certain degree what everyone else on the project is doing.
- Administrators have fine-grained control over who can do what
- It’s far easier to administer a CVCS than it is to deal with local databases on every client.

Disadvantage:
- The single point of failure that the centralized server represents. If that server goes down for an hour, then during that hour nobody can collaborate at all or save versioned changes to anything they’re working on

Distributed Version Control Systems:
Clients don’t just check out the latest snapshot of the files; rather, they fully mirror the repository, including its full history. Thus, if any server dies, and these systems were collaborating via that server, any of the client repositories can be copied back up to the server to restore it. Every clone is really a full backup of all the data.


    Distributed VCS Server Computer

            Version Database
                Version5
                Version4
                Version3
                Version2
                Version1
        -   -             -   -
    <-                           ->
   Computer A               Computer B
Version Database          Version Database
    Version5                 Version5
    Version4      <----->    Version4
    Version3                 Version3
    Version2                 Version2
    Version1                 Version1

Git history:
------------
Git began with a bit of creative destruction and fiery controversy.

The Linux kernel is an open source software project of fairly large scope. During the early years of the Linux kernel maintenance (1991–2002), changes to the software were passed around as patches and archived files. In 2002, the Linux kernel project began using a proprietary DVCS called BitKeeper.

In 2005, the relationship between the community that developed the Linux kernel and the commercial company that developed BitKeeper broke down, and the tool’s free-of-charge status was revoked. This prompted the Linux development community (and in particular Linus Torvalds, the creator of Linux) to develop their own tool based on some of the lessons they learned while using BitKeeper. Some of the goals of the new system were as follows:

- Speed
- Simple design
- Strong support for non-linear development (thousands of parallel branches)
- Fully distributed
- Able to handle large projects like the Linux kernel efficiently (speed and data size)

Since its birth in 2005, Git has evolved and matured to be easy to use and yet retain these initial qualities. It’s amazingly fast, it’s very efficient with large projects, and it has an incredible branching system for non-linear development.

How Git Works
-------------

Snapshots, Not Differences:

Other systems think of about the information they store as a set of files and the changes made to each file overtime, this is commonly describe as delta-based version control.

Git doesn't think of or store its data this way. Git thinks of its data more like a series of snapshots of a miniature filesystem. Git basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. To be efficient, if files have not changed, git doesn't store the file again, just a link to the previous identical file it has already stored. Git thinks about its data more like a stream of snapshots.

This makes Git more like a filesystem with some incredibly powerful tools built on top of it, rather than simply a VSC.

Nearly Every Operation Is Local:
Git operations don't need to be only to work in the project and make commits, and is faster that centralized, since we have a entery copy of the files on local.

This means it save faster and work faster, witout the need of internet (not until you connect and make the upload).

Git Has integrity:
Everything in Git is checksummed before it is stored and is then referred to by that checksum. This means it’s impossible to change the contents of any file or directory without Git knowing about it. This functionality is built into Git at the lowest levels and is integral to its philosophy. You can’t lose information in transit or get file corruption without Git being able to detect it.

The mechanism that Git uses for this checksumming is called a SHA-1 hash. This is a 40-character string composed of hexadecimal characters (0–9 and a–f) and calculated based on the contents of a file or directory structure in Git. A SHA-1 hash looks something like this:

24b9da6552252987aa493b52f8696cd6d3b00373

Git Generally Only Adds Data:
When you do actions in Git, nearly all of them only add data to the Git database. It is hard to get the system to do anything that is not undoable or to make it erase data in any way. As with any VCS, you can lose or mess up changes you haven’t committed yet, but after you commit a snapshot into Git, it is very difficult to lose, especially if you regularly push your database to another repository.

This makes using Git a joy because we know we can experiment without the danger of severely screwing things up


The Three States:
Git has three main states that your files can reside in: modified, staged, and committed:

Modified means that you have changed the file but have not committed it to your database yet.

Staged means that you have marked a modified file in its current version to go into your next commit snapshot.

Committed means that the data is safely stored in your local database.

This leads us to the three main sections of a Git project: the working tree, the staging area, and the Git directory.


Working Directory   Staging area    .git Dir(Repo)
        |       Checkout| the project    |
        |<--------------|----------------|
        |Stage fixes    |                |
        |-------------->|   Commit       |
        |               |--------------->|

Git explained:
The working tree (directory)
is a single checkout of one version of the project. These files are pulled out of the compressed database in the Git directory and placed on disk for you to use or modify.

The staging area
is a file, generally contained in your Git directory, that stores information about what will go into your next commit. Its technical name in Git parlance is the “index”, but the phrase “staging area” works just as well.

The Git directory
is where Git stores the metadata and object database for your project. This is the most important part of Git, and it is what is copied when you clone a repository from another computer.

The basic Git workflow goes something like this:

- You modify files in your working tree.

- You selectively stage just those changes you want to be part of your next commit, which adds only those changes to the staging area.

- You do a commit, which takes the files as they are in the staging area and stores that snapshot permanently to your Git directory.

If a particular version of a file is in the Git directory, it’s considered committed. If it has been modified and was added to the staging area, it is staged. And if it was changed since it was checked out but has not been staged, it is modified.

Ways of using Git
------------------
- Command-line tools
- Graphical UI


